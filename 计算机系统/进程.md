# 进程

早期的计算机一次只能执行一个程序。这种程序完全控制系统，并且访问所有资源。而现代计算机允许加载过个程序到内存中，以便于 **并发** 执行

> [!tip] 并发 Concurrency
> **一段时间内** 发生了很多事情；在这段时间的 **某个时刻**，可能只有一件事情发生

为了实现程序的并发执行，需要对程序提供 **更严格的控制** 和 **更好的划分**。这些需求促使 **_进程_** 概念的产生，即 **_进程为执行的程序_**

## 概念

在讨论操作系统时，有个问题是关于 如何称呼所有CPU活动？

+ 批处理系统执行 **作业**( job)

+ 分时系统使用 **用户程序**( user program) 或**任务**( task)

> [!tip] 操作系统中任何时刻都有多个正在运行的程序
> 
>即使单用户系统，用户也能同时运行多个程序：文字处理、网页浏览和电子邮件处理等
>
>即使用户一次只能执行一个程序，操作系统也需要支持本身的内部活动，如内存管理

所有这些活动在许多方面都相似，因此称为 **_进程_**(process)

关于进程的一种非正式说法：**_进程是执行的程序_**

> [!tip] 进程内存结构
> 
> 进程不仅仅只是程序代码，**程序代码只是进程的一部分**，它在进程的内存结构中称为 **_文本段_** 的区域存储。这是 _只读_ 的区域
> 
> 在文本段之上是程序中显示初始化的数据，称为 **_初始化数据段_**，该部分存储了 **显示初始化** 的 _全局变量_ 和 _静态变量_
> 
> 紧接着就是成长未初始化的数据，称为 **_未初始化数据段_(BSS段)**，该部分存储了 _未显示初始化_ 的全局变量和静态变量
> 
> 紧接着就是进程的 **堆** 区域，这个区域是在运行时为对象动态进行内存分配的一块区域，需要我们手动管理
> 
> 在间隔一片连续的内存空间之后，就是进程的 **栈**，它是一块动态增长和收缩的段，由 **_栈帧_** 组成。每当一个函数调用就会在进程的栈区域分配一个栈帧，其中存储了函数的 **局部变量**，**实参** 和 **返回值**
> 
> 栈之后又以小段区域用于存储 **命令行参数** 和 **环境变量** 区域
> 
> 最顶端的内存区域被系统内核管理，用户程序无法直接访问该区域的内存
> 
> 下图展示一个典型的进程的内存结构
> 
> ![[Drawing 2024-08-01 08.35.36.excalidraw|900]]

> [!tip] 程序和进程：**_程序本身不是进程_**
> 
> **程序** 只是 **被动(passive)实体**，如存储在磁盘上包含一系列指令的 **文件**(经常称为可执行文件( executable file))
> 
> **进程** 是 **活动( active)实体**，具有一个 **程序计数器** 用于表示下个执行命令和 **一组相关资源**

**_当一个可执行文件被加载到内存时，这个程序就成为进程_**。两个进程可以是同一个程序创建的进程。每个进程都是独立的，_除了文本段相同外，其余段均不相同_

**_进程在运行时还可以创建许多进程_**。进程本身可以作为一个环境，用于执行其他代码

> [!example] 进程作为执行环境
> 可执行的 Java 程序在 Java 虚拟机(JVM) 中执行。**JVM 就是一个单独的进程**，它会解释其加载的 Java 程序，并根据 Java 代码生成本机的可执行指令

> [!tip] 内核眼中的进程
>
>进程是由内核定义的抽象的实体，并为该实体分配用以执行程序的各项系统资源
>
>从内核角度看，进程由 **用户内存空间** 和 **一系列内核数据结构** 组成
>
>+ **用户内存空间** 包含了 **_程序代码_** 及 **_代码所使用的变量_**
>+ **内核数据结构** 则用于维护 _进程状态信息_
>
> 用于表示进程的内核数据结构称为 **进程控制块**(Process Control Block, **PCB**)，通常包含了下面几个数据
> + **进程标识(PID)**：程序中控制进程使用的标识符，一个整数
> + **虚拟内存表(内存管理信息)**：系统使用的内存系统信息。这类信息可以包括 _基地址_ 和 _界限寄存器的值_、_页表_ 或 _段表_
> + **进程资源使用及其限制**
> + **当前工作目录**
> + **信号传递及其处理的信息**
> + **程序计数器**：指向进程下一条要执行的指令
> + **CPU 寄存器**：进程使用的寄存器中的指
> + **CPU 调度信息(进程状态)**：包括进程优先级、调度队列的指针及其他调度参数
> + **程序的记账**：CPU时间、实际时间、进程数量等
> + **IO状态**：分配给进程的 _IO 设备列表_ 和 _打开文件列表_
> 
>内核中进就是 PCB 和用户内存空间的合集

## 状态

进程在执行时会改变 **状态**。进程状态，部分取决于进程的当前活动。每个进程可能处于以下状态:

+ **新的**(new)：进程正在创建

+ **运行**(running)： 指令正在执行

+ **等待(阻塞)**(waiting)： 进程等待发生某个事件(如I/O完成或收到信号)

+ **就绪**(ready)：进程等待分配处理器

+ **终止**(terminated)： 进程已经完成执行

这些状态名称比较随意，而且随着操作系统的不同而有所不同。不过，它们表示的状态在所有系统上都会出现。有的系统对进程状态定义的更细。重要的是要认识到: 一次只有一个进程可在一个处理器上 **运行**；但是许多进程可处于 **就绪** 或 **等待** 状态。下图显示了一个进程的状态图

![[Drawing 2024-08-01 09.28.24.excalidraw|900]]

> [!tip] 理解进程状态变化：以小车过桥为例
> 假设有许多小车需要过一条单车道的桥梁。这个 **桥梁就相当于 CPU**，**车就相当于进程**。只有进程获得 CPU 它才能处于运行状态。
> 
> 在桥的两端，有工作人员，控制车何时到桥上。这个 **工作人员就相当于调度器**
> 
> 当车到达桥梁口，此时车(进程)就处于就绪状态
> 
> 当工作人员(调度器)放车上桥(进程被调度)，此时车(进程)就处于运行状态
> 
> 当车离开桥之后，此时车通过桥梁完成(进程结束)，此时进程就处于终止状态
> 
> 如果车在桥上发生车祸或者故障(IO等状态)，此时车(进程)需要等待被救援，此时就处于等待状态。如果等待状态的进程占用 CPU ，此时整个进程被阻塞，从而影响其他进程的执行。因此，需要调度器帮助，让进程让出 CPU。这里，可以理解为工作人员将故障的车移出了桥梁
> 
> 工作人员(调度器)完成对车的救援之后，车又可以进行到桥梁上通行，此时车又处于就绪状态，等待工作人员放行
> 

## 调度

程序想要运行，首先需要输入设备将程序和数据装入计算机，程序在计算机上运行完。然后，在通过输出设备输出结果。整个 过程一个 **程序** 从输入到输出在所有环节都是 **独占资源**

> [!tip] 输入和输出阶段 CPU 没有执行任何计算任务，浪费了 CPU 时间
> 实际上输入、输出环节非常慢，而且此时 CPU 没有计算任务，处于 **忙等待**
> 
> 如果下一个程序需要运行，整个过程将再走一遍，这是一个接一个运行的 **串行** 方式

计算机处理 IO 时，会让 CPU 处于忙等待，能否设计一套控制程序运行的技术，来充分利用 CPU 资源？完成这个任务的这就是 **_多道处理程序_**

多道程序的目标就是 **_始终允许某个进程运行_** 以最大化 CPU 利用率。这种想法比较简单。**一个进程执行直到它应等待为止**，通常等待某个I/O请求的完成

> [!tip] 多道处理程序 
> 
> 对于简单的计算机系统，CPU 就处于闲置状态。所有这些等待时间就会浪费，没有完成任何有用工作
> 
> 采用多道程序，试图有效利用这些等待时间。多个进程同时处于内存。当一个进程等待时，操作系统就从该进程接管CPU控制，并将CPU交给另一进程
> 
> 这种方式不断重复。**_当一个进程必须等待时，另一进程接管CPU使用权_**  

### 进程执行(进程行为)

CPU 的调度取决于：进程执行包括 **周期** 进行的 _CPU 执行_ 和 _IO 执行_。进程在这两个状态之间不断交替

> [!tip] 进程执行
> 进程执行从 CPU 执行开始，然后是 IO 执行；接着是另一个 CPU 执行，接着另一个 IO 执行；如此往复，直到最后一个 CPU 执行通过向操作系统请求结束，以便于终止进程
> 
> 下图展示了 CPU 执行和 IO 执行交替的序列
> 
> ![[Drawing 2024-08-01 14.37.51.excalidraw|900]]
> 
> 

上图中，进程 A 花费了绝大多数时间在 CPU 执行上，而进程 B 则在 IO 执行上花费了较多时间

> [!tip] 计算密集型任务和 IO 密集型任务
> 
> 对于像进程 A 那样花费绝大多数时间在 CPU 执行上的进程，称为  **_计算密集型进程_**
> + 计算密集型进程的特征就是：_较**长时间**处于 CPU 执行_ 和 _**较小频率** 的 IO 执行_
> 
> 对于像进程 B 那样在 IO执行上花费绝大多数时间的进程，称为 **_IO密集型进程_**
> + IO 密集型进程的特征就是：_较 **短时间** 处于 CPU 执行_ 和 _**高频率** 的 IO 执行_
>   
>  CPU 变得越来越快，更多的进程倾向为 IO 密集型。由于 CPU 的改进比磁盘(或网络)改进快得多，从而导致未来对 IO 密集型进程的调度处理更加重要
>   
>  所以，进程调度的基本思想：如果需要运行 IO 密集型进程，那么就应该让它尽快运行，以便于发出 IO请求(磁盘请求或网络请求)，以便于保持磁盘或网络始终忙绿

### 何时调度

调度处理的第一个关键问题是 _何时进行调度决策_。存在需要调度处理的 $4$ 种情形

> [!tip] 调度需要处理的 $4$ 种情形
> 
> 第一：在创建一个新进程之后，需要决定运行父进程还是子进程。父进程 `fork` 一个子进程之后，这两个进程多处于就绪状态，所以这是一个正常的调度决策，可以任意决定。也就是说，**_调度程序可以合法的选择先运行父进程还是先运行子进程_**
> 
> 第二：在一个进程退出时必须做出调度决策。一个进程不再运行(因为它不存在了)，所以必须从就绪进程中选择另外某个进程（**_进程结束时，必须调度一个就绪进程_**）。如果没有就绪进程，通常会运行一个系统提供的空闲进程
> 
> 第三：**当一个运行的进程 _被阻塞_ 时(可能由于：IO、信号量、其他原因)，必须 _调度一个就绪进程_ 运行**。阻塞原因也会成为调度进程的因素。例如，进程 A 是一个重要进程，需要等待进程 B 退出临界区域。让进程 B 运行就会使得进程 B 退出临界区域，从而使得进程 A 可以执行。
> 
> 第四：**当 IO 中断发生时，必须调度一个就绪进程**。如果中断来自 IO 设备，而该设备现在完成了工作，某些被阻塞的等待该 IO 的进程就可能成为就绪进程，是否让新就绪的进程运行，就取决于调度器

如果硬件时钟提供了周期性中断，在每个时钟中断或者每 $k$ 个时钟中断时做出调度决策。根据如何处理时钟中断，可以吧调度分为两类: **_非抢占式_** 和 **_抢占式_**

> [!tip] 非抢占式和抢占式调度
> 非抢占式调取：挑选一个进程后，让该进程运行直到或者被阻塞、或者自动释放 CPU。即使该进程需要运行若干个小时，它也不会被强迫挂起
> + 时钟中断时不会进行调度
>   
> + 在处理完时钟中断之后，如果没有更高优先级的就绪进程到来时，则被中断的进程会继续执行
> 
>抢占式调度：挑选一个进程，并且让该进程运行某个固定时间片。如果时间片到时该进程没有结束，则它被挂起，而调度程序会挑选另一个就绪进程运行。
>+ 进程进行抢占式调度处理，需要在时间片的末端发生时间中断，以便将 CPU 控制返回给调度程序
>  
>+ 如果没有可用的时钟，那么非抢占式调度就是唯一的选择

### 怎么调度(调度算法)

在不同的环境需要不同的调度策略。出现这样的情形是由于不同的应用领域有不同的目标。也就是说，不同的系统中，调度程序的优化是不同的。根据应用领域不同，可以将环境划分为三种：批处理、交互式和实时

> [!tip] 三种系统环境：批处理、交互式、实时
> 
> **批处理系统**中，不会有用户不耐烦地在终端旁等待一个短请求的快捷响应。因此，**非抢占式调度**，或者对每个进程都有 **长时间周期的抢占式调度**，通常都是可接受的
> 
> 在 **交互式用户环境** 中，**为了避免一个进程霸占 CPU 拒绝为其他进程服务，抢占是必须得**。即便没有进程想要永远运行，但是，某个进程由于一个进程错误也可能无限期的排斥其他进程。为了避免这样的情况发生，抢占也是必须得
> 
> 在实时系统中，抢占有时是不需要的，因为进程了解它们可能会长时间的得不到运行，所以通常会很快完成工作并阻塞

不同环境中的调度算法考虑的方面有所不同，但是它们有共同的特点。下面列出来各自系统需要考虑的问题

![[Pasted image 20240801160429.png|900]]

#### 批处理系统中的调取

批处理系统中最常用的调度算法有三种：**先来先服务**，**最短作业优先**，**最短剩余时间优先**

##### 先来先服务

最简单的 CPU 调度算法是 **_先到先服务_**( First-Come First-Served, FCFS)调度算法。采用这种方案，**先请求 CPU 的进程首先分配到 CPU**。FCFS策略可以通过FIFO队列容易地实现

> [!tip] FCFS 实现
> 
> 当一个进程进入就绪队列时，它的 PCB 会被链接到队列尾部。当 CPU 空闲时，它会分配给位于队列头部的进程，并且这个运行进程从队列中移去。FCFS调度代码编写简单并且理解容易

FCFS策略的缺点是非常明显的，**_平均等待时间_ 往往很长**。假设有如下一组进程，它们在时间 0 到达，CPU 执行长度按 `ms` 计 

|  进程   | 执行时间 |
| :---: | :--: |
| $P_1$ |  24  |
| $P_2$ | $3$  |
| $P_3$ | $3$  |

如果进程按 $P_1, P_2, P_3$ 的顺序到达，并且按 FCFS 顺序处理，那么得到如下 **Gantt 图** 所示的结果(这种 Gantt 图为条形图，用于显示调度情况，包括每个进程的开始与结束时间)

![[Drawing 2024-08-01 16.14.39.excalidraw|900]]

进程 $P_1$ 的等待时间为 `0ms`，进程 $P_2$ 的等待时间为 `24ms`，而进程 $P_3$ 的等待时间为 `27ms`。因此，平均等待时间为`(0 + 24+ 27)/3= 17ms`

> [!tip] FCFS 的缺点
> 
> 假设有一个一次运行 `1s` 的计算密集型进程和很少使用 CPU 但是没够都要运行 $1000$ 磁盘读操作才能完成的大量 IO 密集型进程存在。
> 
> 计算密集型进程运行 $1$ 秒钟，接着读取一个磁盘块，所有 IO 进程开始运行并读取磁盘
> 
> 当计算密集型进程获得其磁盘块是，它运行下一个 $1$ 秒钟，紧跟其后的是所有 IO 进程
> 
> 这样的结果就是：每个 IO 进程在每秒钟读到一个磁盘块，要花费 $1000$ 秒钟才能完成
> 
> 

---

##### 最短作业优先

另一个不同的 CPU 调度方法是 **_最短作业优先_**(Shortest-Job-First，**SJF**)调度算法。这个算法将每个进程与其下次 CPU 执行的长度关联起来。当 CPU 变为空闲时，它会被赋给具有最短 CPU 执行的进程。如果两个进程具有同样长度的 CPU 执行，那么可以由 FCFS 来处理  

> 注意，一个更为恰当的表示是 **最短下次 CPU 执行**( shortest-next-CPU-burst)算法，这是因为调度取决于进程的下次 CPU 执行的长度，而不是其总的长度

作为一个 SJF 调度的例子，假设有如下一组进程，CPU 执行长度以 `ms` 计


|  进程   | 执行时间 |
| :---: | :--: |
| $P_1$ | $6$  |
| $P_2$ | $8$  |
| $P_3$ | $7$  |
| $P_4$ | $3$  |

采用 SJF 调度，就会根据如下 Gantt 图来调度这些进程

![[Drawing 2024-08-01 16.34.58.excalidraw|900]]

进程 $P_1$ 的等待时间是 `3ms`，进程 $P_2$ 的等待时间为 `16ms`，进程 $P_3$ 的等待时间为`9ms`，进程 $P_4$ 的等待时间为 `0ms`。因此，平均等待时间为`(3 + 16 + 9+ 0)/4 = 7ms`。相比之下，如果使用 FCFS 调度方案，那么平均等待时间为 `10.25ms`

SJF 算法的困难之处在于如何确定下一次 CPU 执行的长度。一种方法是试图近似 SJF 调度。_虽然不知道下一个 CPU执行的长度，但是可以预测它_。可以认为下一个CPU 执行的长度与以前的相似。因此，通过计算下一个 CPU 执行长度的近似值，可以选择具有预测最短 CPU 执行的进程来运行

>[!tip] 下次 CPU 执行长度的预测
>下次 CPU 执行长度通常预测为 _以前 CPU 执行的测量长度的 **指数平均**_
>
>可以按下面的公式来计算指数平均。设 $t_n$ 为第 $n$ 个CPU执行长度，设 $\tau_{n+1}$ 为下次CPU执行预测值。因此，对于 $a，0\le a \le 1$ , 定义
> 
> $$\tau_{n+1} = at_{n} + (1-a)\tau_{n}$$ 
>
>值 $t_n$ 包括最近信息，而 $\tau_n$ 存储了过去历史。参数 $a$ 控制最近和过去历史在预测中的权重
>
> + 如果 $a=0$ ，那么 $\tau_{n+1}=\tau_n$ ，最近历史没有影响(当前情形为瞬态)
> + 如果 $a= 1$ ，那么 $\tau_{n+1}=t_n$ ,只有最近CPU执行才重要(过去历史被认为是陈旧的、无关的)
> 
>更为常见的是， $a=1/2$ ，这样最近历史和过去历史同样重要。初始值 $\tau_0$ 可作为常量或系统的总体平均值

##### 最短剩余时间优先

**抢占 SJF 调度** 有时称为 **最短剩余时间优先**(Shortest-Remaining-Time-First，SRTF) 调度

当一个新进程到达就绪队列而以前进程正在执行时，就需要选择了。**新进程的下次CPU 执行长度，与当前运行进程的尚未完成的 CPU 执行长度相比，可能还要小**，抢占 SJF 算法会抢占当前运行进程

作为例子，假设有以下 $4$ 个进程，其 CPU 执行时间以 `ms` 计

|  进程   | 到达时间 | 执行时间 |
| :---: | :--: | :--: |
| $P_1$ | $0$  | $8$  |
| $P_2$ | $1$  | $4$  |
| $P_3$ | $2$  | $9$  |
| $P_4$ | $3$  | $5$  |

如果进程按给定时间到达就绪队列，而且需要给定执行时间，那么产生的抢占 SJF 调度如以下 Gantt 图所示

![[Drawing 2024-08-01 16.52.32.excalidraw|900]]

进程 $P_1$ 在时间 $0$ 开始，因为这时只有进程 $P_1$。进程 $P_2$ 在时间 $1$ 到达。进程 $P_1$ 剩余时间( `7ms` )大于进程 $P_2$ 需要的时间( `4ms` )，因此进程 $P_1$ 被抢占，而进程 $P_2$ 被调度对于这个例子，平均等待时间为 `[(10-1)+(1-1) + (17-2) + (5-3)]/4 = 26/4 = 6.5ms`。如果使用非抢占SJF调度，那么平均等待时间为 `7.75ms`

#### 交互式系统中的调度

交互式系统在个人计算机、服务器中最为常用

##### 轮转调度

**轮转调度** 是使用最广泛的一种最简单、最公平的调度算法。每个进程被分配一个时间段，称为 **时间片**，运行该进程在该时间片内运行。如果在时间片结束时该进程还在运行，则将剥夺 CPU 并分配给其他进程。如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换

 时间片的大小通常为 `10 ~ 100ms`。 就绪队列实现为循环队列。CPU 调度程序循环整个就绪队列，**为每个进程分配不超过一个时间片的 CPU**

时间片轮转调度唯一难点就是时间片大小如何确定。从一个进程切换到另一个进程需要一定的时间进行 _现场保护_ 和 _现场恢复_

> [!tip] **现场保护** 和 **现场恢复**
> 
> 现场保护：保存寄存器中的值，更新各种与进程相关的内核数据结构，可能需要将进程换出内存
> 
> 现场恢复：装入寄存器的值以及内存映像，可能需要重新调入内存

**进程间切换** 有时也称为 **上下文切换**，假设这个过程需要 $1$ 毫秒。如果时间片设为 $4$ 毫秒，则 CPU 在做完 $4$ 毫秒的有用工作后，CPU 间花费 $1$ 毫秒完成上下文切换。因此，CPU 时间的 $20\%$ 被浪费了

为了提高 CPU  利用率，将时间片设置为 $100$ 毫秒，这样只浪费 $1\%$。但是，如果在一段非常短的时间间隔内到达 $50$ 个请求并且对 CPU 有不同的需求，那么在一个服务系统中会发生什么呢？$50$ 个进程会放在可运行的列表中。如果 CPU 是空闲的，第一个进程会立即开始执行，第二个直到 $100$ 毫秒之后才会启动。假设所有进程都用完了它们的时间片，那么最后一个进程获得运行机会之前奖不得不等待 $5$ 秒。

> [!tip] 时间片的长短会影响调度性能
> 
> 时间片设置太短会导致进程切换频繁，从而降低 CPU 效率
> 
> 时间片设置太长可能引起对短的交互请求的响应时间边长
> 
> 一个合理时间片在 $20 \sim 50$ 毫秒

##### 优先级调度

SJF 算法是通用 **优先级调度** 算法的一个特例。每个 **进程** 都有一个 **优先级与其关联**，而具有 **_最高优先级的进程会分配到 CPU_**。具有相同优先级的进程按 FCFS 顺序调度。SJF 算法是一个简单的优先级算法，其优先级(`p`)为下次(预测的) CPU 执行的倒数。**CPU 执行越长，则优先级越小**；反之亦然

注意，如果按照高优先级和低优先级讨论调度。优先级通常为固定区间的数字，如`0~7`或`0~4095`。不过，对于 $0$ 表示最高还是最低的优先级没有定论

有的系统用低数字表示低优先级，其他用低数字表示高优先级。这种差异可以导致混淆。我的讨论中，**_用低数字表示高优先级_**

作为例子，假设有如下一组进程，它们在时间 $0$ 按顺序 `P1，P2, ..., P5`到达，其CPU 执行时间以 `ms` 计

|  进程   | 执行时间 | 优先级 |
| :---: | :--: | :-: |
| $P_1$ | $10$ | $3$ |
| $P_2$ | $1$  | $1$ |
| $P_3$ | $2$  | $4$ |
| $P_4$ | $1$  | $5$ |
| $P_5$ | $5$  | $2$ |

采用优先级调度，会按如下 Gantt 图来调度这些进程:

![[Drawing 2024-08-01 17.35.19.excalidraw|900]]

平均等待时间为 `8.2ms`


优先调度可以是 **_抢占的_** 或 **_非抢占的_**。当一个进程到达就绪队列时，比较它的优先级与当前运行进程的优先级。如果新到达进程的优先级高于当前运行进程的优先级，那么抢占优先级调度算法就会 **抢占 CPU**。非抢占优先级调度算法只是将新的进程 **加到就绪队列的头部**

> [!tip] 优先级调度算法的一个主要问题是 **_无穷阻塞_** 或 **_饥饿_**
> 就绪运行但是等待 CPU 的进程可以认为是阻塞的。优先级调度算法可让某个低优先级进程无穷等待 CPU
> 
> 对于一个超载的计算机系统，稳定的更高优先级的进程流可以阻止低优先级的进程获得 CPU
> 
> 低优先级进程的无穷等待问题的解决方案之一是 **老化**，即：**_逐渐增加在系统中等待很长时间的进程的优先级_**

##### 多级队列调度

在进程容易分成不同组的情况下，可以有另一类调度算法。例如，进程通常分为 **_前台进程_** (也可称为 _交互进程_)和 **_后台进程_**(也称为 _批处理进程_)。这两种类型的进程 **具有不同的响应时间要求**，进而也有 **不同调度需要**。另外，与后台进程相比，前台进程可能要有更高的优先级

**多级队列** 调度算法 **将就绪队列分成多个单独队列**。根据进程属性，如内存大小、进程优先级、进程类型等，一个进程永久分到一个队列。每个队列有自己的调度算法

> [!tip] 不同的就绪队列有不同调度算法
> 有两个队列分别用于前台进程和后台进程
> + 前台队列可以采用 RR 算法调度
> + 后台队列可以采用 FCFS 算法调度
> 

此外，**_队列之间应有调度_**，通常采用固定优先级抢占调度。例如，前台队列可以比后台队列具有绝对的优先

_在队列之间划分时间片_。每个队列都有一定比例的 CPU 时间，可用于调度队列内的进程

> [!tip] 队列也可以进行时间片轮转调度
> 
> 例如，对于 **_前台_ —_后台_ 队列** 的例子，前台队列可以有 `80%` 的CPU 时间，用于在进程之间进行 RR 调度，而后台队列可以有 `20%` 的CPU时间，用于按FCFS算法来调度进程

#####  多级反馈队列调度

**通常在使用多级队列调度算法时，进程进入系统时被永久地分配到某个队列**。例如，如果前台和后台进程分别具有单独队列，那么进程并不从一个队列移到另一个队列，这是因为进程不会改变前台或后台的性质。这种设置的优点是调度开销低，缺点是不够灵活

相反，**多级反馈队列** 调度算法 **_允许进程在队列之间迁移_**。这种想法是，根据不同 CPU 执行的特点来区分进程。如果进程使用过多的 CPU 时间，那么它会被移到更低的优先级队列

> [!tip] 这种方案将 IO 密集型和交互进程放在更高优先级队列上

此外，在较低优先级队列中等待过长的进程会被移到更高优先级队列。**这种形式的老化阻止饥饿的发生**

#### 实时系统中的调度

我不考虑实时系统中的调度问题。因为我也接触不到实时系统


## 创建

Linux 系统调用 `fork()` 就可以创建一个进程。这个子进程完完全全就是父进程的一个拷贝。

> [!tip] `fork()` 采用写时复制技术加速进程的创建
> 
> `fork()` 调用之后，子进程与父进程共享物理内存，这些物理内存被标记为只读。当子进程或者父进程要写入数据时，才会对写入数据的内存段进行复制
> 

```c
#include <stdio.h>
#include <string.h>
#include <errno.h>

#include <sys/types.h>    // 提供 pid_t 的定义
#include <unistd.h>  // 提供 fork() 的函数原型


static int idata = 111;  // 在进程的初始化数据段

int main() {

    int istack = 222;  // 在进程的 main 函数的栈帧中

    pid_t child_pid;

    switch (child_pid = fork())
    {
    case -1: // 创建子进程失败
        fprintf(stderr, "fork failed: %s\n", strerror(errno));
        break;
    
    case 0:  // fork 在子进程中返回 0
        idata *= 3;
        istack *= 3;
        break;

    default: // 在父进程中返回 子进程的 pid
        sleep(3);
        break;
    }
    // 父子进程都会执行此处的代码
    printf("PID=%ld %s idata=%d istack=%d\n", (long)getpid(), (child_pid == 0) ? "(childe)": "(parent)", idata, istack);
    return 0;
}
```

使用 GCC 编译运行的结果为

```shll
$ gcc process.c 
$ ./a.out 
PID=78492 (childe) idata=333 istack=666
PID=78491 (parent) idata=111 istack=222
```

> [!tip] `fork()` 函数会返回两次
> 
> 在调用进程中返回一次，这一次返回的结果就是结果 `fork` 创建进程的 PID
> 
> 在 `fork` 创建的进程中，`fork` 还会返回一次，这一次返回值是 $0$
  
通过分析输出结果，发现 `fork()` 出来的子进程拥有了自己的 _栈_ 和 _数据段_，且其对这些段中变量的修改将不会影响父进程。如下图所示

![[Drawing 2024-08-01 20.54.27.excalidraw|900]]

## 进程间通信

从上述演示可以看出，两个进程的内存是隔离的，因此需要提供额外的机制，让两个进程之间交换数据(进程同步)

**在 _同一个虚拟内存地址_，在不同的进程中，会被映射到不同的物理内存区域，因此在多个进程之间通过虚拟地址交换数据是不可能完成的**。鉴于进程之间天然的内存壁垒，想要实现多个进程间交换数据，就必须提供一种专门的机制，也就是所谓的 **进程间通信机制**

Linux 系统上提供了较为完整的 _通信_ 和 _同步_ 工具，他们被划分为了三类。如下图所示

![[Pasted image 20240801212810.png|900]]

